{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32c2469",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "c32c2469",
    "outputId": "976e4ed7-2e1d-4cdb-cc65-7d7b945b3cba"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import keyword\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from extract import SocialETL, construct_query_for_twarc, extract_tags, SocialDB, UserETL\n",
    "import hashtags as h\n",
    "import hashtags_readcsv as r_csv\n",
    "from rich import print\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "from rich.table import Table\n",
    "#import warnings \n",
    "#warnings.filterwarnings('always')   #suppresses all warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from extract import extract_tags\n",
    "from rich import print\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb62e4a",
   "metadata": {
    "id": "fcb62e4a"
   },
   "source": [
    "## 1 parte: categorizzazione hashtags per prorus, proukr, pax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacac27",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f0e55ea83f7f499a9750c10ddee2225c"
     ]
    },
    "id": "cbacac27",
    "outputId": "5965e42c-5bc2-44b3-fb16-cdf7af779d4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Reading secret from C:\\Users\\david\\Documents\\GitHub\\ds-network-analysis\\data\\my_secrets.yaml…\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c9914c3850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e55ea83f7f499a9750c10ddee2225c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rate limit exceeded: sleeping 110.18333053588867 secs\n",
      "rate limit exceeded: sleeping 124.55334281921387 secs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; font-weight: bold\">79429</span> tweets retrieved\n",
       "with query <span style=\"color: #008000\">'#slavaukraini OR #istandwithputin OR #stopwarinukraine'</span>\n",
       "of which <span style=\"color: #000080; font-weight: bold\">79426</span> tweets with at least <span style=\"color: #000080; font-weight: bold\">1</span> hashtag.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c9914c3be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">We have <span style=\"color: #000080; font-weight: bold\">7636</span> unique hashtags.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c99a67f3a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000\">Let</span><span style=\"color: #800000\">'s write the describe of column '</span><span style=\"color: #800000\">slavaukraini'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c990d01ff0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">count     <span style=\"color: #000080; font-weight: bold\">79426</span>\n",
       "unique        <span style=\"color: #000080; font-weight: bold\">2</span>\n",
       "top        <span style=\"color: #00ff00; font-style: italic\">True</span>\n",
       "freq      <span style=\"color: #000080; font-weight: bold\">70052</span>\n",
       "Name: slavaukraini, dtype: object\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c993f538b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000\">Let</span><span style=\"color: #800000\">'s write the describe of column '</span><span style=\"color: #800000\">istandwithputin'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c993f53760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">count     <span style=\"color: #000080; font-weight: bold\">79426</span>\n",
       "unique        <span style=\"color: #000080; font-weight: bold\">2</span>\n",
       "top       <span style=\"color: #ff0000; font-style: italic\">False</span>\n",
       "freq      <span style=\"color: #000080; font-weight: bold\">78719</span>\n",
       "Name: istandwithputin, dtype: object\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c993f53790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000\">Let</span><span style=\"color: #800000\">'s write the describe of column '</span><span style=\"color: #800000\">stopwarinukraine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c993f53880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">count     <span style=\"color: #000080; font-weight: bold\">79426</span>\n",
       "unique        <span style=\"color: #000080; font-weight: bold\">2</span>\n",
       "top       <span style=\"color: #ff0000; font-style: italic\">False</span>\n",
       "freq      <span style=\"color: #000080; font-weight: bold\">70521</span>\n",
       "Name: stopwarinukraine, dtype: object\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c993f53c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000\">All done.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1c993f53400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ensure_latin(s): \n",
    "    return (\n",
    "        unicodedata.normalize(\"NFKD\", s).encode(\"latin-1\", \"ignore\").decode(\"latin-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "def construct_query_for_pandas(root_tags: list) -> str:\n",
    "    my_query = \" or \".join(root_tags)\n",
    "    return my_query\n",
    "\n",
    "\n",
    "def create_score(df: pd.DataFrame, one_hashtag: str, root_tags: dict) -> list:\n",
    "    # takes a df of all tweets, each row is a tweet, each column is\n",
    "    # a hashtag either [True | False] depending on whether the hashtag\n",
    "    # is in the tweet. Takes one_hashtag, the hashtag to score, and\n",
    "    # root_tags, a dict of {category: [hashtags]}\n",
    "    # TODO: make it so it accepts a list of {category: [hashtags]} instead of just one\n",
    "    threshold_support = 0.5 * len(df) / 10000  # set the threshold_support here!!\n",
    "\n",
    "    if threshold_support < 1:\n",
    "        threshold_support = 1\n",
    "    # print(f\"Looking for {one_hashtag} with support {threshold_support}…\")\n",
    "    mask = df[one_hashtag]\n",
    "    df = df[mask]\n",
    "    # print(f\"I found {len(df)} tweets with {one_hashtag}\")\n",
    "    if len(df) < threshold_support:\n",
    "        return False\n",
    "    \"\"\"for col in df:\n",
    "        if df[col].any():\n",
    "            print(f\"We have {col} hashtag\")\"\"\"\n",
    "    results = []\n",
    "    # START OF TESTING:\n",
    "    \"\"\"    print(df.info())\n",
    "    print(df.describe())\n",
    "    print(df.head())\n",
    "    print(f\"[purple]Dude, here's the breakdown:\")\n",
    "    for tag in root_tags.values():\n",
    "        print(f\"[blue]This is {tag[0]}:\")\n",
    "        print(df[tag[0]])\"\"\"\n",
    "    for category, tag_madre in root_tags.items():\n",
    "        try:\n",
    "            my_query = construct_query_for_pandas(tag_madre)\n",
    "            # print(f\"The pandas query is: [red]{my_query}\")\n",
    "            temp_df = df.query(my_query)\n",
    "            # print(f\"Holy jezuz: {len(temp_df)} and {len(df)}\")\n",
    "            results.append(round(len(temp_df) / len(df), 4))\n",
    "        except KeyError:\n",
    "            results.append(0)\n",
    "\n",
    "    # print(results)\n",
    "    return (results, len(df))\n",
    "\n",
    "\n",
    "def do_search(tagmadre, pages):\n",
    "    # construct the initial query to Twarc\n",
    "    query_madre = construct_query_for_twarc(tagmadre)\n",
    "    m = SocialETL(\n",
    "        query=f\"({query_madre})\",\n",
    "        pages=pages,\n",
    "        recent=False,\n",
    "    )\n",
    "\n",
    "    # dropping any tweets with no hashtags (I think)\n",
    "    tweets_with_hashtag = m.df[[\"id\", \"entities.hashtags\"]].dropna()\n",
    "    print(\n",
    "        f\"{len(m.df)} tweets retrieved\\nwith query '{query_madre}'\\nof which {len(tweets_with_hashtag)} tweets with at least 1 hashtag.\"\n",
    "    )\n",
    "\n",
    "    # evaluate the string in \"entities.hashtags\" to an actual list of dicts\n",
    "    tweets_with_hashtag[\"entities.hashtags\"] = tweets_with_hashtag[\n",
    "        \"entities.hashtags\"\n",
    "    ].map(eval)\n",
    "\n",
    "    # make a simple list of strings, one hashtag is one string, into column \"tags\"\n",
    "    tweets_with_hashtag[\"tags\"] = tweets_with_hashtag[\"entities.hashtags\"].map(\n",
    "        extract_tags\n",
    "    )\n",
    "    tweets_with_hashtag = tweets_with_hashtag.drop(columns=\"entities.hashtags\")\n",
    "\n",
    "    # hashtags: EXPLODE *musica dei power ranger*\n",
    "    all_hashtags = set(tweets_with_hashtag[\"tags\"].explode())\n",
    "\n",
    "    # keyword level: eliminate all python keywords from columns because otherwise we are in no man's land\n",
    "    keywordsss = keyword.kwlist\n",
    "    keywordsss.extend(keyword.softkwlist)\n",
    "    all_hashtags = all_hashtags.difference(keywordsss)\n",
    "    all_hashtags = all_hashtags.difference(set((\"\",)))\n",
    "\n",
    "    print(f\"We have {len(all_hashtags)} unique hashtags.\")\n",
    "\n",
    "    tweets_with_hashtag.set_index(\"id\", inplace=True)\n",
    "\n",
    "    col_h = sorted(list(all_hashtags))\n",
    "    df_h = pd.DataFrame(columns=col_h)\n",
    "    tweets_with_hashtag = pd.concat([tweets_with_hashtag, df_h], axis=1)\n",
    "    tweets_with_hashtag = tweets_with_hashtag.fillna(False)\n",
    "\n",
    "    def assign_hashtag_to_tweet(row: pd.Series) -> pd.Series:\n",
    "        for tag in row[\"tags\"]:\n",
    "            if tag in all_hashtags:\n",
    "                row.loc[tag] = True\n",
    "        return row\n",
    "\n",
    "    tweets_with_hashtag = tweets_with_hashtag.apply(assign_hashtag_to_tweet, axis=1)\n",
    "    tweets_with_hashtag = tweets_with_hashtag.drop(columns=[\"tags\"])\n",
    "\n",
    "    for madre in tagmadre.values():\n",
    "        print(f\"[red]Let's write the describe of column '{madre[0]}'\")\n",
    "        print(tweets_with_hashtag[madre[0]].describe())\n",
    "\n",
    "    tweets_with_hashtag.to_csv(f\"twee_hash_{pages}.csv\")\n",
    "    print(\"[green]All done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # params\n",
    "    top_results_to_take = 3\n",
    "    pages_to_do = 800\n",
    "\n",
    "    # set the initial \"parent\" hashtags for each category\n",
    "    tag_madre = {\n",
    "        \"proukr\": [\"slavaukraini\"],\n",
    "        \"prorus\": [\"istandwithputin\"],\n",
    "        \"pax\": [\"stopwarinukraine\"],\n",
    "    }\n",
    "\n",
    "    # code\n",
    "    # first run\n",
    "    do_search(tag_madre, pages_to_do)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b46de9",
   "metadata": {
    "id": "42b46de9"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('twee_hash_800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b3bed",
   "metadata": {
    "id": "1c9b3bed",
    "outputId": "6583d7c0-a4c0-4d01-b06c-61b08dfb8d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79426, 7637)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4bfbd",
   "metadata": {
    "id": "cbe4bfbd",
    "outputId": "f7ab608a-d296-457b-dcd0-d3e9331547c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>08cykla</th>\n",
       "      <th>1000ai</th>\n",
       "      <th>100millionsdemorts</th>\n",
       "      <th>101st</th>\n",
       "      <th>10percentforthebigguy</th>\n",
       "      <th>13luglio</th>\n",
       "      <th>14juillet</th>\n",
       "      <th>14juillet2022</th>\n",
       "      <th>15july2022</th>\n",
       "      <th>...</th>\n",
       "      <th>znazis</th>\n",
       "      <th>zolkin</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zsu</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zusammenhalten</th>\n",
       "      <th>zustimmung</th>\n",
       "      <th>zwar</th>\n",
       "      <th>zwastika</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1555959736935251969</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1555959615136976897</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1555959613626925057</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1555959517011116033</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1555959220692033537</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1555959209031860227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1555959146658369539</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1555959123124043782</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1555959043314925568</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1555959032392867842</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7637 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  08cykla  1000ai  100millionsdemorts  101st  \\\n",
       "0  1555959736935251969    False   False               False  False   \n",
       "1  1555959615136976897    False   False               False  False   \n",
       "2  1555959613626925057    False   False               False  False   \n",
       "3  1555959517011116033    False   False               False  False   \n",
       "4  1555959220692033537    False   False               False  False   \n",
       "5  1555959209031860227    False   False               False  False   \n",
       "6  1555959146658369539    False   False               False  False   \n",
       "7  1555959123124043782    False   False               False  False   \n",
       "8  1555959043314925568    False   False               False  False   \n",
       "9  1555959032392867842    False   False               False  False   \n",
       "\n",
       "   10percentforthebigguy  13luglio  14juillet  14juillet2022  15july2022  ...  \\\n",
       "0                  False     False      False          False       False  ...   \n",
       "1                  False     False      False          False       False  ...   \n",
       "2                  False     False      False          False       False  ...   \n",
       "3                  False     False      False          False       False  ...   \n",
       "4                  False     False      False          False       False  ...   \n",
       "5                  False     False      False          False       False  ...   \n",
       "6                  False     False      False          False       False  ...   \n",
       "7                  False     False      False          False       False  ...   \n",
       "8                  False     False      False          False       False  ...   \n",
       "9                  False     False      False          False       False  ...   \n",
       "\n",
       "   znazis  zolkin  zombies    zsu  zucker  zurich  zusammenhalten  zustimmung  \\\n",
       "0   False   False    False  False   False   False           False       False   \n",
       "1   False   False    False  False   False   False           False       False   \n",
       "2   False   False    False  False   False   False           False       False   \n",
       "3   False   False    False  False   False   False           False       False   \n",
       "4   False   False    False  False   False   False           False       False   \n",
       "5   False   False    False  False   False   False           False       False   \n",
       "6   False   False    False  False   False   False           False       False   \n",
       "7   False   False    False  False   False   False           False       False   \n",
       "8   False   False    False  False   False   False           False       False   \n",
       "9   False   False    False  False   False   False           False       False   \n",
       "\n",
       "    zwar  zwastika  \n",
       "0  False     False  \n",
       "1  False     False  \n",
       "2  False     False  \n",
       "3  False     False  \n",
       "4  False     False  \n",
       "5  False     False  \n",
       "6  False     False  \n",
       "7  False     False  \n",
       "8  False     False  \n",
       "9  False     False  \n",
       "\n",
       "[10 rows x 7637 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e97661",
   "metadata": {
    "id": "76e97661",
    "outputId": "15fdb31a-8f3f-461b-997a-cf943f9d110a"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16104\\780940454.py\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m# code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;31m# first run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mend_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags_support\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_madre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages_to_do\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m# second run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16104\\780940454.py\u001b[0m in \u001b[0;36mdo_search\u001b[1;34m(tagmadre, pages)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagmadre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# construct the initial query to Twarc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mtweets_with_hashtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"twee_hash_800.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# hashtags: EXPLODE *musica dei power ranger*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1421\u001b[0m     \"\"\"\n\u001b[0;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ensure_latin(s):\n",
    "    return (\n",
    "        unicodedata.normalize(\"NFKD\", s).encode(\"latin-1\", \"ignore\").decode(\"latin-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "def construct_query_for_pandas(root_tags: list) -> str:\n",
    "    my_query = \" or \".join(root_tags)\n",
    "    return my_query\n",
    "\n",
    "\n",
    "def create_score(df: pd.DataFrame, one_hashtag: str, root_tags: dict) -> list:\n",
    "    # takes a df of all tweets, each row is a tweet, each column is\n",
    "    # a hashtag either [True | False] depending on whether the hashtag\n",
    "    # is in the tweet. Takes one_hashtag, the hashtag to score, and\n",
    "    # root_tags, a dict of {category: [hashtags]}\n",
    "    # TODO: make it so it accepts a list of {category: [hashtags]} instead of just one\n",
    "    threshold_support = 1.9 * len(df) / 10000  # set the threshold_support here!!\n",
    "\n",
    "    if threshold_support < 1:\n",
    "        threshold_support = 1\n",
    "    # print(f\"Looking for {one_hashtag} with support {threshold_support}…\")\n",
    "    mask = df[one_hashtag]\n",
    "    df = df[mask]\n",
    "    # print(f\"I found {len(df)} tweets with {one_hashtag}\")\n",
    "    if len(df) < threshold_support:\n",
    "        return False\n",
    "    \"\"\"for col in df:\n",
    "        if df[col].any():\n",
    "            print(f\"We have {col} hashtag\")\"\"\"\n",
    "    results = []\n",
    "    # START OF TESTING:\n",
    "    \"\"\"    print(df.info())\n",
    "    print(df.describe())\n",
    "    print(df.head())\n",
    "    print(f\"[purple]Dude, here's the breakdown:\")\n",
    "    for tag in root_tags.values():\n",
    "        print(f\"[blue]This is {tag[0]}:\")\n",
    "        print(df[tag[0]])\"\"\"\n",
    "    for category, tag_madre in root_tags.items():\n",
    "        try:\n",
    "            my_query = construct_query_for_pandas(tag_madre)\n",
    "            # print(f\"The pandas query is: [red]{my_query}\")\n",
    "            temp_df = df.query(my_query)\n",
    "            # print(f\"Holy jezuz: {len(temp_df)} and {len(df)}\")\n",
    "            results.append(round(len(temp_df) / len(df), 4))\n",
    "        except KeyError:\n",
    "            results.append(0)\n",
    "\n",
    "    # print(results)\n",
    "    return (results, len(df))\n",
    "\n",
    "\n",
    "def do_search(tagmadre, pages):\n",
    "    # construct the initial query to Twarc\n",
    "    tweets_with_hashtag = pd.read_csv(Path(\"twee_hash_800.csv\"), index_col=0)\n",
    "\n",
    "    # hashtags: EXPLODE *musica dei power ranger*\n",
    "    all_hashtags = set(tweets_with_hashtag.columns)\n",
    "\n",
    "    # keyword level: eliminate all python keywords from columns because otherwise we are in no man's land\n",
    "    keywordsss = keyword.kwlist\n",
    "    keywordsss.extend(keyword.softkwlist)\n",
    "    all_hashtags = all_hashtags.difference(keywordsss)\n",
    "    all_hashtags = all_hashtags.difference(set((\"\",)))\n",
    "\n",
    "    # up to here we have only dealt with a dataframe of tweets. Now we switch to dataframe of hashtags\n",
    "\n",
    "    # create a dataframe with all hashtags and their scores\n",
    "    all_hashtags_as_dict = {}\n",
    "    supp = {}\n",
    "    for hashtag in track(all_hashtags):\n",
    "        # discard based on support\n",
    "        pass\n",
    "        # calculate scores only on hashtags with enough support\n",
    "        score = create_score(tweets_with_hashtag, hashtag, tagmadre)\n",
    "        if score is not False:\n",
    "            # score[0] is the scores, score[1] is the support\n",
    "            all_hashtags_as_dict[hashtag] = score[0]\n",
    "            supp[hashtag] = score[1]\n",
    "    all_hashtags_df = pd.DataFrame.from_dict(\n",
    "        all_hashtags_as_dict, orient=\"index\", columns=tagmadre\n",
    "    )\n",
    "\n",
    "    # now, \"categorize\" hashtags. The hashtag gets the category of its max score,\n",
    "    # as long as it is > `threshold_certainty`\n",
    "    # TODO: remember that we still need to account for hashtag support\n",
    "    # (i.e. number of tweets supporting that hashtag)\n",
    "    threshold_certainty = 0.5\n",
    "    tags_categorized = defaultdict(list)\n",
    "    for hashtag, scores in all_hashtags_df.iterrows():\n",
    "        # print(hashtag, scores)  # TODO: check if the scores are different enough among 3 categories\n",
    "        # print(scores.idxmax(), scores.max())\n",
    "        if scores.max() > threshold_certainty:\n",
    "            tags_categorized[scores.idxmax()].append((hashtag, scores.max()))\n",
    "            other_scores = set(scores).difference(set((scores.max(),)))\n",
    "            for sco in other_scores:\n",
    "                if scores.max() < 1.2 * sco:\n",
    "                    print(f\"Attention. For {hashtag} the scores are\\n{scores}\")\n",
    "\n",
    "    # tags_categorized.sort(key=lambda x: x[1], reverse=True)\n",
    "    \"\"\"    tags_categorized = {\n",
    "        k: sorted(v, key=lambda item: item[1], reverse=True)\n",
    "        for k, v in tags_categorized.items()\n",
    "    }\"\"\"\n",
    "\n",
    "    return tags_categorized, supp\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # params\n",
    "    top_results_to_take = 3\n",
    "    pages_to_do = 300\n",
    "\n",
    "    # set the initial \"parent\" hashtags for each category\n",
    "    tag_madre = {\n",
    "        \"proukr\": [\"slavaukraini\"],\n",
    "        \"prorus\": [\"istandwithputin\"],\n",
    "        \"pax\": [\"stopwarinukraine\"],\n",
    "    }\n",
    "\n",
    "    # code\n",
    "    # first run\n",
    "    end_results, tags_support = do_search(tag_madre, pages_to_do)\n",
    "\n",
    "    # second run\n",
    "    \"\"\"\n",
    "    end_results = {\n",
    "        k: [x[0] for x in v[:top_results_to_take]] for k, v in end_results.items()\n",
    "    }\n",
    "    print(\"miao\", end_results)\n",
    "    end_results = do_search(end_results)\n",
    "    \"\"\"\n",
    "\n",
    "    with open(f\"hashtags_{pages_to_do}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(end_results, f, ensure_ascii=False, indent=4)\n",
    "    with open(f\"supports_{pages_to_do}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tags_support, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d52fc1",
   "metadata": {
    "id": "51d52fc1",
    "outputId": "25000970-a017-4fe8-ed7f-98147022db4c"
   },
   "outputs": [],
   "source": [
    "with open('hashtags_300.json', 'r') as f:\n",
    "    my_dict = json.load(f)\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ae485",
   "metadata": {
    "id": "905ae485"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prova_creazione_rete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
